---
title: "STAT 537 HW 8"
author: "Doug Anderson and Brandon Fenton and Kenny Flagg"
date: 'April 6, 2016'
output:
  pdf_document: default
  word_document: null
---



_Due on Wednesday, April 6, at 5 pm. You can work in a group of up to three but at least one group member needs to be different from the last assignment._

_Continuing with Chang, Hansen, and Piekielek (2014), we will explore EFA of the variables._

_For this work, we will continue to drop pack7 and pack8 which are almost always 0s (see code below)._


```{r setup, echo=F, warning=F,message=F}
# load packages and data
require(pander)
require(psych)

knitr::opts_chunk$set(echo=F, warning=F, message=F, cache=T, comment=NA, size="footnotesize", fig.width=6, fig.height=4, fig.align="center", dev="pdf", dev.args=list(pointsize=8))
panderOptions("round", 5)

# tc1<-read.csv("https://montana.box.com/shared/static/m5tv7r4ce7mw3w0vyqu0q7i1f8jflkkc.csv",header=T) #Data set without any modifications from https://knb.ecoinformatics.org/#view/doi:10.5063/F1DZ067F
tc1 <- read.csv("tcdata.csv")
tc1$responsef<-factor(tc1$response)
tc1_r<-tc1[,c(4:39,64:75)]

#table(tc1_r$pack7)
#table(tc1_r$pack8)

tc2<-tc1_r[,-c(43,44)]

require(GPArotation) #Or else you'll have problems with fa()
```

1) _Use fa.parallel from the psych package to consider how many factors you should use with the Q=46 variables. Discuss the results. How many factors would you use and why?_

```{r p1_a, results="asis"}
fa2 <- fa.parallel(tc2)
```
\hspace{-0.4em}.

```{r p1_b, dependson="p1_a", results="asis"}
eigentable <- rbind(Eigenvalue = fa2$fa.values,
                    Proportion = (fa2$fa.values^2)/sum(fa2$fa.values^2),
                    `Cum. Prop.` = cumsum(fa2$fa.values^2)/sum(fa2$fa.values)^2)
pander(eigentable[,1:7], caption = "First 7 FA Eigenvalues")
```

The latent root criterion suggests using the number of factors equal to the number of eigenvalues that are greater than 1. If we use that strategy, we would use four factors. If we consider the proportion of the total variance explained divided by the sum of the total variance of the variables, we would find that the first eigenvalue is sufficient to get the proportion of variability over 90%. If we consider the the plot formed from Horn's parallel analysis, we would consider between 5 factors. 

2) _Generate a varimax rotated two-factor solution and provide a path diagram with simple=T as an option. Name and interpret the two factors using a simple structure interpretation._

```{r p2_a, dependon="p1_a", fig.height=3, fig.width=3, out.width="4.5in", out.height="4.5in"}
fa.varimax <- fa(tc2, rotate="varimax", nfactors=2)
fa.diagram(fa.varimax, simple=T)
```

MR1 is positively associated with all of the temperature variables, and has negative associations with the summer snowpack and precipitation variables (with the exception of June precipitation). This is the overall temparature factor.

MR2 is positively associated with all the remaining variables; however, the association with June precipitation is weak ($\lambda=0.4)$. The other variables are precipitation and snowpack for fall, winter, and spring, so MR2 is the winteriness factor.

3) _What does the likelihood ratio test suggest about a two factor solution in this output? Make sure to report hypotheses tested, test statistic, distribution under the null, and p-value._

The likelihood ratio test evaluates the data under the null model that two factors are sufficient, with a distributional assumption of $\chi^2_{`r fa.varimax$null.dof`}$.  The test statistic is $\chi^2_{`r fa.varimax$dof`} = `r fa.varimax$STATISTIC`$, and the resultant p-value is less than 0.0001, suggesting that two factors are not sufficient for these data.





\pagebreak
4) _In this solution, which two manifest variables are least explained? How did you determine this?_

```{r p4_a}
u.vals <- sort(fa.varimax$uniquenesses, decreasing = T)
top.uv <- t(data.frame(u.vals[1:8]))
rownames(top.uv) <- "Uniqueness"
emphasize.strong.cols(c(1,2))

pander(top.uv, caption = "First 8 Uniquenesses")
```

The uniquenesses associated with __pack6__ and __ppt5__ are the largest, so these are the least explained of the manifest variables under this model.  Since $\hat{u}_i^2= 1 - \hat{h}_i^2$, where $\hat{h}_i^2$ is the communality of the ith variable, we could also arrive at this conclusion by finding the two smallest communalities.

5) _Now make a path diagram with the simple=F option but try cutting off displaying paths with the option cut=0.4 and then cut=0.5. Discuss generally how things changed. Do not attempt a detailed interpretation of the solution but do discuss whether your previous names of the factors would need to change based on this updated diagram._

```{r p5_a, dependon="p2_a", fig.height=3, fig.width=4.5, out.width="4.5in", out.height="4.5in"}
par(mfrow = c(1, 2))
fa.diagram(fa.varimax, simple=F, cut = 0.4)
mtext(expression("Cutoff: "*lambda==0.4), 3, 1)
fa.diagram(fa.varimax, simple=F, cut = 0.5)
mtext(expression("Cutoff: "*lambda==0.5), 3, 1)
```

The pattern of which variables are most closely associated with which factors has not changed from problem 2, so the factors can still be described as "overall temperature" and "winteriness." The big difference is that the simple=F option allows variables to be linked to both factors, greatly complicating the interpretation. This is remedied by increasing the cutoff, omitting variables which are weakly associated with one or both factors. There is an associated decrease in parsimony, since it is implie that these variables correspond to additional latent factors that we have not accounted for.

\pagebreak
6) _Consider a promax rotation with 2 factors and remake the simple=T path diagram. How did the two factors change? Provide names for the two factors if they are different from the varimax version._

```{r p6_a, dependon="p5_a", fig.height=3, fig.width=4.5, out.width="4.5in", out.height="4.5in"}
par(mfrow = c(1, 2))
fa.promax <- fa(tc2, rotate="promax", nfactors=2)
fa.diagram(fa.varimax, simple=T)
mtext("Varimax", 3, 1)
fa.diagram(fa.promax, simple=T)
mtext("Promax", 3, 1)
```

Each latent factor is associated with the same manifest variables as before, but now the factors have a moderate negative correlation of -0.6. The signs of the loadings are the same, but the magnitudes of the largest loadings are now slightly larger. MR1 is still "overall temperature" and MR2 is still "winteriness" but the promax solution tells us that higher winteriness is associated with lower temperatures.

7) _Check your two poorly explained manifest variables. Did the amount of their variation explained change or remain the same? Explain this result._

```{r p7_a, dependson="p4_a"}
u.vals2 <- sort(fa.promax$uniquenesses, decreasing = T)
top.uv2 <- t(data.frame(u.vals[1:6], u.vals2[1:6]))
rownames(top.uv2) <- c("Varimax Uniqueness", "Promax Uniqueness")
emphasize.strong.cols(c(1,2))

pander(top.uv2, caption = "First 6 Uniquenesses")
```

The uniquenesses do not change because the rotation is simply a change of basis. This can change which factors a variable is associated with, but does not affect the amount of variation explained by all the factors.

\pagebreak
8) _Repeat the path diagram with simple=F, leaving the path display cutoff at the default setting. What is the default cutoff setting? How did the promax non-simple display compare to the results from varimax? How can you explain these differences in complexity of solutions?_

```{r p8_a, dependon="p6_a", fig.height=3, fig.width=4.5, out.width="4.5in", out.height="4.5in"}
par(mfrow = c(1, 2))
fa.diagram(fa.varimax, simple=F)
mtext("Varimax", 3, 1)
fa.diagram(fa.promax, simple=F)
mtext("Promax", 3, 1)
```

The plot on the left shows the varimax result and the plot on the right shows the promax result, both using the default cutoff of 0.3. Since we specified simple=F, double loadings are shown in the plots. The varimax rotation results in many double loadings, and in many cases the weaker loading for the variable is negative. The promax solution has only one double loading, and it is positive. The negative associations are instead represented by the negative correlation between the latent factors, which makes the promax solution easier to interpret.


## R Code Appendix:
Problem 1:
```{r a1, ref.label='p1_a', eval=F, echo=T}
```

```{r b1, ref.label='p1_b', eval=F, echo=T}
```

Problem 2:
```{r a2, ref.label='p2_a', eval=F, echo=T}
```

\pagebreak
Problem 4:
```{r a4, ref.label='p4_a', eval=F, echo=T}
```

Problem 5:
```{r a5, ref.label='p5_a', eval=F, echo=T}
```

Problem 6:
```{r a6, ref.label='p6_a', eval=F, echo=T}
```

Problem 7:
```{r a7, ref.label='p7_a', eval=F, echo=T}
```

Problem 8:
```{r a8, ref.label='p8_a', eval=F, echo=T}
```
